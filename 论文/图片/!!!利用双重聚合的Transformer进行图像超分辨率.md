https://arxiv.org/abs/2308.03364

Https://github.com/zhengchen1999/DAT

全局关系的建立，对高分辨率图像的重建尤为重要，但是，全局 SA 的计算复杂度与图像大小成平方比，这极大限制了其在高分辨率图像上的应用。

1. 空间方面，局部空间窗口被提出来限制全局 SA 的应用范围，从而提出局部窗口注意力 (Spatial-Window Self-Attention，SW-SA)。如图 (a)，空间维度 HxW 被划分为多个窗口，注意力在每个窗口中被执行。
2. 通道方面，提出通道自注意力 (Channel-WiseSelf-Attention，CW-SA)。如图 (b)，注意力沿着通道维度计算。也就是图中每一个独立的块都作为一个Token.
![[Pasted image 20240316201137.png]]

这些方法都在降低计算复杂度的同时，实现优异的性能。同时这两种方法对于图像特征 (H x W xC )的建模，是针对不同 (空间与通道)的维度的。那么，是否可以同时考虑两个维度，在现有方法的基础上，进一步提高 Transformer 的建模能力，实现更加出色的超分辨率性能呢?

受以上发现的启发，我们提出 DAT (Dual Aggregation Transformer)，通过块间和块内双重方式，实现空间和通道特征有效融合。具体来说，我们在连续的 Transformer 块中交替应用 SW-SA 和 CW-SA 。通过这在交替的方式，DAT 能够同时捕获空间和通道信息，实现块间特征聚合。同时，为了实现块内特征聚合，我们还提出自适应交互块 (Adaptive Interaction Module，AIM)和空间门前馈网络 (Spatial-Gate Feed-forward NetworkSGFN)。AIM 对 SW-SA 和 CW-SA 建模单一维度进行改进，SGFN 则在前馈网络中引入非线性空间信息。

<font color="#00b050">模型架构</font>
![[Pasted image 20240316202936.png]]

DAT 包含三个模块：浅层特征提取，深层特征提取和图像重建模块。
<font color="#00b050">自适应交互模块 AIM</font>
![[Pasted image 20240316203346.png]]
我们提出的 AIM 对 SW-SA 和 CW-SA 进一步进行改进，考虑到自注意力主要是捕获全局特征，增加了与自注意力模块平行的卷积分支，依次引入局部性到 transformer 中。接着考虑到虽然交替执行 SW-SA 和 CW-SA 可以在块间实行空间与通道的特征聚合，但是对于每个自注意力 SA 而言，不同维度的信息仍然无法有效利用，因此提出了 AIM，作用于两个分支之间，并根据分支的类型，从空间或通道维度自适应地重新加权特征，从而在单个注意力模块中实现空间和通道信息的聚合。

<font color="#00b050">空间门前馈网络 SGFN</font>
![[Pasted image 20240316205032.png]]
传统的前馈网络 (Feed-ForwardNetwork，FFN)有线性层和非线性激活组成。只能够对特征通道进行建模，但忽略了建模空间信息。此外，FFN 会通过线性层在内部对特征通道进行放大，这导致通道之间存在冗余，从而阻碍了特征表达能力。

为了克服上述问题，我们提出了 SGFN:将空间门控 (Spatial-Gate，SG)引入到 FFN 中。SG 是一个简单的门空机制，由深度卷积和逐元素乘法组成。同时，我们将特征图沿着通道维度，均匀的分为两个部分，分别送入卷积和乘法旁路中，以此来降低通道余性。并且该操作也能有效降低计算复杂度。

整体来看，AIM 和 SGFN 是 Transformer 块的两个主要组成。通过这个两个模块，我们实现块内的特征聚合:
	AIM 从通道维度增强 SW-SA，并从空间维度增强 CW-SA。
	SGFN 将非线性空间信息引入仅建模通道关系的 FFN 中。