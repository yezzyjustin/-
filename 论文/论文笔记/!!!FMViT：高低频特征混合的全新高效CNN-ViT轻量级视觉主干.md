https://github.com/tany0699/FMViT

下图说明了全面的 FMViT 体系结构。FMViT 采用传统的金字塔结构，每个级包括一个下采样模块和一个仅带卷积的卷积融合模块 (CFB)或带 transformer 的多频混合模块 (FMB)。该干将空间分辨率降低到原始输入图像的四分之一，并且每个后续阶段逐步将空间分辨率减半，同时逐渐增加通道数量。我们探索了信息交互模块，并受到 MetaFormer 的启发，引入了卷积融合模块 (CFB)来解决短期数据依赖关系。提出了一种多频混合模块 (FMB)，通过对多个频段进行分解，进一步融合本地和全局数据。

![[Pasted image 20240316184904.png]]

这种多通道频率融合增强了模型的建模能力。为了降低多头注意力 (MHSA)的计算复杂度，提出了一种轻量级的 RLMHSA 模块。通过参数共享和重新参数化，在不影响模型精度的前提下，提高了模型的推理速度。这些核心模块开发了一系列 CNN-Transformer 混合架构，在移动端 cpu 和服务器端 gpu 上实现了精度和延迟之间的最佳平衡，超越了最先进的模型。

1. RepMLP 提出了多层感知器 (MLP)的重新参数化。RepMLP 采用 convKxK 融合为 FC，但其权值转换比较稀疏，转换后的参数变成了原来的 KxK 倍，不适合轻量级场景。在 Transformer 中，由于 mlp 具有全局建模功能，因此对性能有很大贡献。然而，局部建模能力的缺乏限制了它的潜力。为了帮助原始卷积进行局部通道的分组建模，在两个原始 CONV (1,1,1)卷积中引入多个具有 G ’ > 1 的并行 conv 1 x 1 卷积，重构 MLP 模块。该方法同时关注来自不同位置的不同表示子空间的信息，以实现高效的局部表示学习。
2. 为了增强MLP中全局方面和局部方面的混合建模，在两个卷积之间加入了深度卷积。一个快捷连接确保了全局和局部信息流不相互干扰，并且添加的深度卷积被重新参数化。实验结果表明，在Imagenet1k上增强深度卷积的局部信息融合能力，使MLP的性能提高了1.96%。

**Convolutional Fusion Block (CFB)**

Transformer模块已经在各种视觉任务中展示了显著的结果，基于注意力的令牌混合器模块和MetaFormer 范式强调了它们固有的优势。然而，Transformer块的推理速度可能更有效，特别是在多头注意力、LayerNorm和GELU计算的性能不是最优的移动设备上。我们已经证明了MetaFormer范式的成功，并在此基础上提出了一个高效的CFB模块，该模块专门使用深度可分离卷积(DWConv)作为令牌混频器。CFB保持了瓶颈块的部署优势，同时实现了与Transformer块相当的性能，如上图所示。CFB使用DWConv和MLP构建，遵循通用的MetaFormer设计。CFB确保了性能，同时显著提高了推理部署性能。此外，在训练过程中实现了重新参数化，以进一步提高CFB的性能，其中DWConv使用了标准的、广泛使用的重新参数化。MLP采用了本文提出的卷积多群重参数化方法。

**Multi-frequency Fusion Block(FMB)**

1. 虽然 CFB 已经有效地学习了地方代表性，但处理全球信息收集的迫切需要仍然存在。Transformer 块捕获低频信号，提供全局信息，如形状和结构。现有的研究表明，Transformer 块可能会部分地减少高频信息，包括局部纹理细节。为了提取更多的基本和独特的特征，来自不同频段的信号必须精心整合，因为它们对人类视觉系统至关重要。
2. 高频信号提供局部信息，这对于保持信息的完整性是不可或缺的。不同的频率特征提供独特的信息，使高频信号容易受到变压器块的退化。各种高频特征与低频特征的融合可以增强模型的信息流和表达能力，灵感来自图像超分辨率中的信息蒸馏和频率混合。如图所示，CFB 模块最初捕获高频特征，随后以不同频率输出三组高频特征。然后采用贴片嵌入融合对轻量级多头注意力模块的输出进行拼接，从而产生高低频信号。通过 MLP 层，可以提取更基本、更显著的特征。下式可表示为:
![[Pasted image 20240316190343.png]]
3. 与 LN 和 GELU 不同，FMB 始终使用 BN 和 ReLU 作为有效规范层和激活层。这些运算符可以有效地计算，特别是在移动设备上，由于其速度友好的性质，性能损失最小。FMB 可以在轻量级框架内收集和集成多频率信息，因此与传统的纯 Transformer 模块相比，显著提高了模型的性能。