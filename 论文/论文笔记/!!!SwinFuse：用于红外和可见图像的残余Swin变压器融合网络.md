SwinFuse: A Residual Swin Transformer Fusion Network for Infrared and Visible Images

https://github.com/Zhishe-Wang/SwinFuse

现有的深度学习融合方法主要集中在卷积神经网络上，很少对变压器进行尝试。同时，卷积运算是图像与卷积核之间的内容无关的交互，可能会丢失一些重要的上下文，进一步限制融合性能。为此，我们提出了一个简单而强大的红外和可见光图像融合基线，即残余 Swin 变压器融合网络，称为 SwinFuse。我们的 SwinFuse 包括三个部分: 全局特征提取、融合层和特征重构。特别地，我们构建了一个全注意力特征编码骨干来建模远程依赖关系，这是一个纯变压器网络，与卷积神经网络相比具有更强的表示能力。
此外，我们设计了一种基于 l 1 范数的序列矩阵特征融合策略，从行向量和列向量维度测量相应的活动水平，可以很好地保留竞争的红外亮度和清晰的可见细节。最后，我们通过主观观察和客观比较，在三个不同的数据集上验证了我们的 SwinFuse 与九种最先进的传统和深度学习方法的融合，实验结果表明，我们提出的 SwinFuse 获得了令人惊讶的融合性能，具有强大的泛化能力和具有竞争力的计算效率。
![[Pasted image 20240419230508.png]]

![[Pasted image 20240419230530.png]]

在融合层，如图 3 所示，我们对红外和可见光图像序列矩阵设计了一种基于 l 1 范数的融合策略，并从行向量和列向量维度测量其活动水平。它们各自的全球特征，称为Φ ir GF (i; j)和Φ对 GF (i; j)，我们首先通过 l 1 范数计算它们的行向量权值，并采用 softmax 得到它们的活动水平，称为“ir row (i)”和“vis row (i)”，如式 8和9所示。

![[Pasted image 20240419231704.png]]
![[Pasted image 20240419231719.png]]

然后，我们直接将它们的活动水平与相应的全局特征相乘，从行向量维度得到融合的全局特征，称为Φ row F (i;j)，由式10表示。
![[Pasted image 20240419231942.png]]

随后，与上述操作类似，我们从列向量维度测量它们的活动水平，称为“ir col (j)”和“vis col (j)”，由公式 11 和 12 表示。
![[Pasted image 20240419232006.png]]
然后，我们可以得到具有列向量维数的融合全局特征，称为Φ col F (i; j)，由式 13 表示。
![[Pasted image 20240419232137.png]]
最后，我们在行向量和列向量维度上对它们的融合全局特征进行逐元素加法运算，得到最终的融合全局特征，由式 14 计算得到。
![[Pasted image 20240419232159.png]]