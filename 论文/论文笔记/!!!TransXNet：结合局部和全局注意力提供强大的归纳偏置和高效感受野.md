TransXNet：learning both global and local dynamics with a dual dynamic token mixer for visual recognition

**<font color="#00b050">基于 MHSA 构建远距离建模实现全局感受野的覆盖，但缺乏像 CNN 般的归纳偏置能力，因此在泛化能力上较弱</font>********

为了使得 VITs 具有归纳偏置，后面大部分工作都选择了构建混合网络，即融合自注意力和卷积操作，然而，标准卷积在这些混合网络中使用，性能改进有限，这是因为卷积核是输入无关的，不能适应不同的输入，从而导致了自注意力和卷积之间的表示能力有限

为了解决上述问题，本文引入一种新的混合网络模块称为 Dual Dynamic Token Mixer，它以一种依赖于输入的方式聚合全局信息和局部信息。输入特征被分为两部分，分别经过一个全局自注意力模块和一个依赖于输入的深度卷积模块进行处理，然后将两个输出连接在一起。

本文还介绍了一个多尺度前馈网络（MS-FFN），它在 Token 聚合过程中探索了多尺度信息。
![[Pasted image 20240314114707.png]]

如上图所示，同大多数主干网而言，TransXNet 网络采用了一个分层的结构，分为四个阶段。每个阶段由一个图像块嵌入层和多个依次堆叠的模块组成。第一个图像块嵌入层使用 7 x 7 的卷积层 (步长=4)，随后是批量归一化 (BN)，而其余阶段的图像块嵌入层使用 3 x 3 的卷积层 (步长=2)和 BN。每个块包括一个动态位置编码 (DPE)层，一个双动态令牌混合器 (D-混合器)，以及一个多重码前馈网络。

<font color="#00b050">Dual Dynamic Token Mixer</font>
为了提高 Transformer 模型的泛化能力并引入归纳偏差，以前的方法已经尝试结合卷积和自注意力来构建混合模型。然而，这些方法中的静态卷积核限制了 Transformer 的输入依赖性。因此，作者提出了一个轻量级的 Token Mixer，称为 Dual Dynamic Token Mixer (o-Mixer)，它可以动态地利用全局和局部信息，同时注入大的感受野和强大的归纳偏差，而不牺牲输入依赖性。

D-Mixer 的工作流程如下图所示。对于一个特征图 X，首先将其沿通道维度均匀分为两个子特征图 X 1和 X 2。然后，X 1和 X 2分别经过一个全局自注意力模块 (OSRA)和一个动态深度卷积模块 (IDConv)，生成相应的特征图然后将它们沿通道维度连接在一起，生成输出特征图 X'。最后，作者使用 squeezed Token Enhancer (STE)来进行有效的局部 token 聚合。
![[Pasted image 20240314121705.png]]

可以看出， D-Mixer 的主要特点是，通过堆叠多个 D-Mixer，0SRA 和 IDconv 生成的动态特征聚合权重同时考虑了全局和局部信息，从而增强了型的表示学习能力。
值得一提的是， D-Mixer 的其中一个关键组成部分是"Input-dependent Depthwise Convolution" (IDConv)，它用于在动态输入依赖方式下注入归纳偏差并执行局部特征聚合。这个 IDConv 通过自适应平均池化来聚合空间上下文，然后通过两个 1 x 1 的卷积层产生注意力图，最终生成输入依赖的深度卷积核。与其他动态卷积方法相比，IDconv 具有更高的动态局部特征编码能力，并且在计算开销上较低。

<font color="#00b050">Overlapping Spatial Reduction Attention</font>
下面简单为大家梳理下 OSRA 模块的计算流程:
	·首先，输入特征图 X 通过 OSR 模块进行处理，产生输出特征图 Y。
	·然后，通过线性变换将 X 映射为査询 (Q)，并将 Y 映射为键 (K)和值 (V)。
	·接下来，通过 split 操作将线性变换后的分成多个部分
	·最后，通过局部细化模块 (LR)和一个相对位置偏置矩阵 (B)进行一些后处理。
这个计算流程可以帮助模型更好地捕捉图像中的空间关系，其中引入了 OSR 来改进对图像边界附近空间结构的建模, 这有助于提高模型在图像识别任务中的性能。

<font color="#00b050">Squeezed Token Enhancer (STE)</font>
STE 主要用于增强 token 之间的交互，同时降低计算成本。在以前的方法中，为了实现 token 之间的交互，通常会使用 1 x 1 卷积层，但这会导致相当大的计算开销。为了降低计算成本而不影响性能，作者引入了该模块。
STE 模块的计算流程如下所示
	·首先，输入特征图 X 通过 3 x 3 深度卷积 (DWConv 3 x 3)进行处理，以增强 token 之间的后部关系。
	·然后，使用通道压缩和扩展的 1 x 1 卷积层，降低计算成本。
	·最后，通过残差连接，将上述两个部分相加，以保留表示能力。

<font color="#00b050">Multi-scale Feed-forward Network</font>
![[Pasted image 20240314122148.png]]

MS-FFN 主要用于在模型的前馈神经网络 (Feed-forward Network)中进行多尺度的特征处理。通常，前馈神经网络 (FFN)用于对输入特征进行特征提取和变换，以提高模型的表示能力。然而，传统的 FFN 可能会受限于单一尺度的特征提取，难以充分利用多尺度的信息。
为了克服这个问题，本文引入了该模块。与传统的 FFN 不同，其采用了多尺度的处理方式。具体来说，MS-FFN 模块使用了四个并行的深度可分离卷积 (depthwise convolution)，每个卷积核的尺度不同，分别是 3 x 3、5 x 5、7 x 7。这四个卷积核分别处理输入特征的四分之一通道。这意味着每个卷积核专门负责处理输入特征的一部分通道，以有效地捕获多尺度的信息。此外，还有一个 1 x 1 深度卷积核，用于学习通道方面的缩放因子。这个 1 x 1 深度卷积核的作用是对通道进行加权缩放，以更好地融合多尺度信息。