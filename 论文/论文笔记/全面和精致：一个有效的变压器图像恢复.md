http://pengxi.me/wp-content/uploads/2023/04/Comprehensive-and-Delicate-An-Efficient-Transformer-for-Image-Restoration.pdf

Comprehensive and Delicate: An Efficient Transformer for Image Restoration

https://github.com/XLearning-SCU/2023-CVPR-CODE

视觉变换在图像恢复中表现出良好的性能，通常进行基于窗口或通道的关注，避免了大量的计算。虽然取得了很好的效果，但是它们捕捉的是像素之间的局部依赖而不是全局依赖，这在一定程度上违背了变形金刚最大的成功因素。在本文中，我们提出了一种新的高效的图像恢复转换器，它首先捕获超像素级的全局依赖关系，然后将其传输到每个像素。这种从粗到精的范式通过两个神经块来实现，即浓缩注意神经块 (CA)和双自适应神经块 (DA)。简而言之，CA 通过特征聚合、注意力计算和特征恢复来有效地捕获超像素级的全局依赖关系。为了实现像素的全局依赖性，数据分析采用了一种新的双向结构，自适应地将全局性从超像素封装到像素。由于有两个神经块，我们的方法与 SwinIR 相比只需要~ 6%的 FLOPs 就能达到相当的性能

![[Pasted image 20240419174415.png]]


**Dual Adaptive Neural Block**
由于三步范式，CA 捕获了超像素的全局依赖关系，并且每个超像素特征都包含丰富的全局信息。然而，在超像素级别上获得这样的全局依赖与像素级全局依赖的最终目标相去甚远。因此，逐像素恢复可以依赖于来自超像素的全局信息。为了解决这一问题，我们引入了双自适应神经块(DA)，通过一种新颖的双向结构和动态加权方式，将超像素全局性封装到像素全局依赖性中。具体来说，DA 首先采用点向卷积 Pmix(·)来混合超像素特征，即
![[Pasted image 20240419174242.png]]
然后，由于每个超像素包含全局信息，DA 引入双向结构，在短范围内捕获每个像素对超像素的依赖关系，同时在局部范围内从超像素的特征中提取像素的特征地区。之后，我们让前者以动态加权的方式作用于后者，即:
![[Pasted image 20240419174543.png]]
式中 i = 1，···，C 为通道索引。简而言之，Φ DW i 从每个通道≈Fi 中提取两个通道切片{≈X 1 i，≈X 2 i}，这是通过核大小为 7 × 7 的群卷积实现的。σ(·)和φ(·)是 Sigmoid 和 GELU 激活，它们分别将依赖关系转换为权重并过滤提取的像素特征。最后，CA 采用逐点卷积 pus (·)对具有全局性的特征进行细化，即:
![[Pasted image 20240419174630.png]]

通过上述设计，数据分析可以通过将全局依赖关系和全局特征从超像素转移到每个像素来捕获逐像素的全局依赖关系，而只引入少量的计算和参数。