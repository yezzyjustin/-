TransNeXt: Robust Foveal Visual Perception for Vision Transformers
https://github.com/DaiShiResearch/TransNeXt


由于残差连接的深度退化效应，许多依赖堆叠层进行信息交换的高效视觉变形模型往往不能形成足够的信息混合，导致视觉感知不自然。为了解决这个问题，在本文中，我们提出了聚合注意力，这是一种基于仿生设计的令牌混合器，它模拟生物中央凹视觉和连续眼运动，同时使特征映射上的每个令牌具有全局感知。此外，我们结合了可学习的令牌，与传统的查询和键交互，这进一步多样化了亲和矩阵的生成，而不仅仅依赖于查询和键之间的相似性。我们的方法不依赖于堆叠进行信息交换，从而有效地避免了深度退化，实现了自然的视觉感知。
此外，我们提出了卷积 GLU，一种通道混频器，它弥合了 GLU 和 SE 机制之间的差距，它使每个令牌基于其最近邻图像特征获得通道关注，增强了局部建模能力和模型鲁棒性。我们将聚合注意力和卷积 GLU 结合起来，创建了一个名为 TransNeXt 的新视觉主干。

![[Pasted image 20240419180323.png]]


**Convolutional GLU**
<font color="#00b050">motivation</font>
ViT 时代的通道门控注意: 以“挤压-激励”(Squeeze-and-Excitation, SE)机制为代表的前人研究[25]首次将通道注意引入计算机视觉领域，使用具有激活函数的支路对网络输出进行门控。在门控通道注意中，门控支路比值支路有更大的决策权，最终决定相应的输出元素是否为零。从这个角度来看，SE 机制巧妙地使用全局平均池化后的特征作为门控分支的输入，实现了最大的接受野以更好地决策，同时解决了 cnn 结构中接受野不足的问题。然而，在 ViT 时代，全球接受域不再稀缺。以自关注为代表的各种全局令牌混合器实现了比全局平均池化更高质量的全局信息聚合。
这使得 SE 机制所使用的全局池化方法显示出一些缺点，例如该方法使特征映射上的所有令牌共享相同的门控信号，使得其通道关注缺乏灵活性且过于粗粒度。尽管如此，值得注意的是，ViT 结构缺乏渠道关注。最近的研究[74]发现，在通道混频器中加入 SE 机制可以有效地增强模型的鲁棒性，如图4所示。
![[Pasted image 20240419180130.png]]
ViT 时代的卷积: 最近的研究[8,27]表明，在视觉转换器中引入 3 × 3 深度卷积[6]可以被视为条件位置编码 (CPE)的一种形式[8]，可以有效地从零填充中捕获位置信息。

<font color="#00b050"> Rethinking Channel Mixer Design</font>
1. 门控线性单元 (GLU)[11,51]是一种通道混频器，已被证明在各种自然语言处理任务中优于多层感知器 (MLP)。GLU 由两个线性投影组成，这两个线性投影是逐元素相乘的，其中一个投影由一个门控函数激活。与 SE 机制不同，它的每个令牌的门控信号来自令牌本身，并且没有比值分支更大的接受域。
2. 更优雅的设计: 我们发现只需在 GLU 门控分支的激活函数前加入最小形式的 3 × 3 深度卷积，就可以使其结构符合门控通道注意的设计理念，并将其转化为基于最近邻特征的门控通道注意机制。我们将这种方法命名为卷积 GLU，如图 4所示。
3. 特征分析: 基于其最近的细粒度特征，卷积 GLU (ConvGLU)中的每个令牌都具有唯一的门控信号。这解决了 SE 机制中全局平均池过于粗粒度的缺点。同时也满足了一些没有位置编码设计的 ViT 模型需要深度卷积提供位置信息的需求。而且，本设计的价值分支仍然保持了与 MLP 和 GLU 相同的深度，使其具有反向传播友好性。当参数体积与卷积前馈 (ConvFFN)[62]保持一致，展开比为 R，卷积核大小为 k×k 时，ConvGLU 的计算复杂度为 2 RHW C 2 + 2 3 RHW Ck 2，小于 ConvFFN 的 2 RHW C2 +RHW Ck2。
这些特性使 ConvGLU 成为一个简单但更坚固的混合器，满足 vit 的各种要求。